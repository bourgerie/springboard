{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d936854",
   "metadata": {},
   "source": [
    "# Data Wrangling "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a0df48",
   "metadata": {},
   "source": [
    "This is for the second capstone project. The project goal is to predict whether tweets are discussing an actual disaster based on the text -- it is from this kaggle challenge: https://www.kaggle.com/c/nlp-getting-started/overview\n",
    "\n",
    "The datases are provided, but need cleaning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0f80a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "567e5cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw data \n",
    "test_data = pd.read_csv('C:/Users/bourg/OneDrive/Documents/springboard/NLP getting started/test.csv')\n",
    "train_data = pd.read_csv('C:/Users/bourg/OneDrive/Documents/springboard/NLP getting started/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c679771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7613 entries, 0 to 7612\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        7613 non-null   int64 \n",
      " 1   keyword   7552 non-null   object\n",
      " 2   location  5080 non-null   object\n",
      " 3   text      7613 non-null   object\n",
      " 4   target    7613 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 297.5+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3263 entries, 0 to 3262\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        3263 non-null   int64 \n",
      " 1   keyword   3237 non-null   object\n",
      " 2   location  2158 non-null   object\n",
      " 3   text      3263 non-null   object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 102.1+ KB\n"
     ]
    }
   ],
   "source": [
    "#first compare the two\n",
    "train_data.info()\n",
    "test_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a15ea98",
   "metadata": {},
   "source": [
    "I was already aware that train_data had an extra column, target -- this is for the judgments on whether or not the text/tweet is about a disaster or not (it will contain a 1 or a 0). The training data contains this info, and the test data does not yet have it. \n",
    "\n",
    "The 'id' column is an accurate representation for how many rows there actually are -- which means both have quite a lot of location data missing and some keywords missing. I am not sure at this point how important those datapoints are. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "84d40d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'keyword', 'location', 'text', 'target'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "train_data.head()\n",
    "print(train_data.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5034692f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7613.000000</td>\n",
       "      <td>7613.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5441.934848</td>\n",
       "      <td>0.42966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3137.116090</td>\n",
       "      <td>0.49506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2734.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5408.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8146.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10873.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id      target\n",
       "count   7613.000000  7613.00000\n",
       "mean    5441.934848     0.42966\n",
       "std     3137.116090     0.49506\n",
       "min        1.000000     0.00000\n",
       "25%     2734.000000     0.00000\n",
       "50%     5408.000000     0.00000\n",
       "75%     8146.000000     1.00000\n",
       "max    10873.000000     1.00000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.describe()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "365e36d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id           int64\n",
       "keyword     object\n",
       "location    object\n",
       "text        object\n",
       "target       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6434b8cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id             0\n",
       "keyword       61\n",
       "location    2533\n",
       "text           0\n",
       "target         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c0684b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.33272034677525286\n",
      "0.008012610009194798\n"
     ]
    }
   ],
   "source": [
    "missing_locs = train_data['location'].isna().sum()\n",
    "missing_key = train_data['keyword'].isna().sum()\n",
    "loc_na = missing_locs/7613\n",
    "key_na = missing_key/7613\n",
    "print(loc_na)\n",
    "print(key_na)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecc0f08",
   "metadata": {},
   "source": [
    "Over 33% of the location data is missing; less than one percent of the keywords are missing. At this point, the spots need to be either filled in with place holder data, or dropped. \n",
    "\n",
    "I will drop those rows with missing keywords, because there are so few. I will fill the location data with NaN values and try to proceed from there, editing if need be. I want to avoid dropping those rows if possible because it's such a large chunk of the data, but for the same reason, I don't want to extrapolate data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f46af2",
   "metadata": {},
   "source": [
    "# Dropping rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f711853b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of          id  keyword                       location  \\\n",
       "31       48   ablaze                     Birmingham   \n",
       "32       49   ablaze  Est. September 2012 - Bristol   \n",
       "33       50   ablaze                         AFRICA   \n",
       "34       52   ablaze               Philadelphia, PA   \n",
       "35       53   ablaze                     London, UK   \n",
       "...     ...      ...                            ...   \n",
       "7578  10830  wrecked                            NaN   \n",
       "7579  10831  wrecked              Vancouver, Canada   \n",
       "7580  10832  wrecked                        London    \n",
       "7581  10833  wrecked                        Lincoln   \n",
       "7582  10834  wrecked                            NaN   \n",
       "\n",
       "                                                   text  target  \n",
       "31    @bbcmtd Wholesale Markets ablaze http://t.co/l...       1  \n",
       "32    We always try to bring the heavy. #metal #RT h...       0  \n",
       "33    #AFRICANBAZE: Breaking news:Nigeria flag set a...       1  \n",
       "34                   Crying out for more! Set me ablaze       0  \n",
       "35    On plus side LOOK AT THE SKY LAST NIGHT IT WAS...       0  \n",
       "...                                                 ...     ...  \n",
       "7578   @jt_ruff23 @cameronhacker and I wrecked you both       0  \n",
       "7579  Three days off from work and they've pretty mu...       0  \n",
       "7580  #FX #forex #trading Cramer: Iger's 3 words tha...       0  \n",
       "7581  @engineshed Great atmosphere at the British Li...       0  \n",
       "7582  Cramer: Iger's 3 words that wrecked Disney's s...       0  \n",
       "\n",
       "[7552 rows x 5 columns]>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_data.dropna(subset=['keyword'], inplace=True)\n",
    "train_data.info\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649b6817",
   "metadata": {},
   "source": [
    "# Checking for duplicates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754b9b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = train_data.duplicated()\n",
    "#duplicates.to_csv(r'C:/Users/bourg/OneDrive/Documents/springboard/duplicates.csv')\n",
    "\n",
    "#there are no duplicates\n",
    "print(duplicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5440676b",
   "metadata": {},
   "source": [
    "# Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3185748",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b90f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete all non alphanumeric values\n",
    "train_data['text'] = train_data['text'].replace(r'[^0-9a-zA-Z:,\\s]', '', regex=True)\n",
    "\n",
    "#strips extra whitespace and makes all lowercase by column\n",
    "train_data['text'] = train_data['text'].str.strip().str.lower()\n",
    "\n",
    "\n",
    "train_data['keyword'] = train_data['keyword'].str.strip().str.lower()\n",
    "train_data['location'] = train_data['location'].str.strip().str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c383f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2854cf",
   "metadata": {},
   "source": [
    "# Stop words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68e3871",
   "metadata": {},
   "source": [
    "I am considering removing stop words using NLTK; for now I am leaving them in, unless I can find a compelling reason not to. I don't yet know what my process will be moving forward. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fcfd6c",
   "metadata": {},
   "source": [
    "# Test file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ae5417",
   "metadata": {},
   "source": [
    "Doing it all again, but with the test file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5d6232c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3263.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5427.152927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3146.427221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2683.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8176.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10875.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id\n",
       "count   3263.000000\n",
       "mean    5427.152927\n",
       "std     3146.427221\n",
       "min        0.000000\n",
       "25%     2683.000000\n",
       "50%     5500.000000\n",
       "75%     8176.000000\n",
       "max    10875.000000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c4c3d59a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id           int64\n",
       "keyword     object\n",
       "location    object\n",
       "text        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3b80a6c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id             0\n",
       "keyword        0\n",
       "location    2472\n",
       "text           0\n",
       "target         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3da33e",
   "metadata": {},
   "source": [
    "There are no missing keywords, so there is no need to drop rows right now. But It would be very difficult to drop empty location rows because they make up 82% of the test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2ba2bccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>heard about earthquake is different cities, st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>apocalypse lighting spokane wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>typhoon soudelor kills 28 in china and taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0     NaN      NaN                 just happened a terrible car crash\n",
       "1   2     NaN      NaN  heard about earthquake is different cities, st...\n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
       "3   9     NaN      NaN              apocalypse lighting spokane wildfires\n",
       "4  11     NaN      NaN      typhoon soudelor kills 28 in china and taiwan"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cleaning\n",
    "#delete all non alphanumeric values\n",
    "test_data['text'] = test_data['text'].replace(r'[^0-9a-zA-Z:,\\s]', '', regex=True)\n",
    "\n",
    "#strips extra whitespace and makes all lowercase by column\n",
    "test_data['text'] = test_data['text'].str.strip().str.lower()\n",
    "\n",
    "\n",
    "test_data['keyword'] = test_data['keyword'].str.strip().str.lower()\n",
    "test_data['location'] = test_data['location'].str.strip().str.lower()\n",
    "\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26db9d0e",
   "metadata": {},
   "source": [
    "# Export files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "75d265f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.to_csv(r'C:/Users/bourg/OneDrive/Documents/springboard/NLP getting started/cleaned/test_data_clean.csv')\n",
    "train_data.to_csv(r'C:/Users/bourg/OneDrive/Documents/springboard/NLP getting started/cleaned/train_data_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38387191",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
